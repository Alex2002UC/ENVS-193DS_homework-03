---
title: "HW-3"
author: "Alexa Andrade"
format: html
editor: visual
link to github repositroy: https://github.com/Alex2002UC/ENVS-193DS_homework-03 
excecute:
 warning: false
 message: false
---

```{r}
#Reading in all the packages 
library(tidyverse)
library(here)
library(gt)
library(flextable)
library(janitor)
library(readxl)
library(tidyverse)
library(here)
library(readxl)
library(dplyr)
library(flextable)

options(warn = -1)


```

\## Part 2. Problems

### Problem 1. Personal data (30 points)

#### a. Data summarizing (5 points)

I could take and compare the mean time I spent cooking on school days and non-school days because I tend to more homework and have to attend classes during the week, so I think I would spend more time cooking during the weekend.

::: callout-tip
Try committing and pushing your changes here! Write an \_informative\_ commit message.
:::

#### b. Visualization (10 points)

```{r Caclulating Summary Statistics}

Cooking_clean <- read_xlsx(here("Data", "Cooking_timeF.xlsx")) |> #Reading in my data and putting it into a new object name
clean_names() #Running the function clean_names to standarize my column names

Cooking_summary <- Cooking_clean |> #Creating a summary object
  group_by(school_day) |>  #grouping the statistics by Y or N for school day
  summarise(
    mean = mean(minutes_spent_cooking_min),        # Calculate mean time spent cooking
    n = n(),                              # Count number of observations
    sd = sd(minutes_spent_cooking_min),            # Calculate standard deviation
    se = sd / sqrt(n),                   # Calculate standard error
    ci_lower = mean - qt(0.975, df = n - 1) * se,  # 95% CI lower bound
    ci_upper = mean + qt(0.975, df = n - 1) * se   # 95% CI upper bound
  ) |>
  mutate(
    across(c(mean, sd, se, ci_lower, ci_upper), ~round(.x, 1))  # Round values to first decimal point 
  ) |>
  select(school_day, mean, sd, se, ci_lower, ci_upper)  # Select final columns I want shown 
```

```{r Visualizing Data}

ggplot(data = Cooking_clean, aes(x = school_day, y = minutes_spent_cooking_min, color = school_day)) + #Setting up data for plotting
  geom_jitter(width = 0.2, height = 0, alpha = 0.6, shape = 21, 
              aes(fill = school_day, color = "black")) +  # Adds raw data points with jitter plot, shows the underlying data 
  
  geom_errorbar(data = Cooking_summary, #Adds error bars determined by SE
                aes(x = school_day, ymin = mean - se, ymax = mean + se),
                width = 0.2, #width of error bars
                inherit.aes = FALSE,
                color = "black") +  # Error bars for mean ± SE, colored black
  
  geom_point(data = Cooking_summary, #Adds mean points on top of the error bars 
             aes(x = school_day, y = mean),
             inherit.aes = FALSE,
             color = "black", 
             size = 3) +  # Size of the mean points
  
  labs(x = "Status of Day",  #Adding Axis labels and subtitle
       y = "Average Time Spent Cooking(min)", 
       title = "Mean time spent cooking During the Week",
       subtitle = "Alexa Andrade") +
  
scale_x_discrete(labels = c("N" = "Non-School Day", "Y" = "School Day")) + #Renaming the x-axis 
  scale_color_manual(values = c("School Day" = "steelblue", "Non-School Day" = "red")) + #manually changing the colors of non-school and school categories
    
    
    
  theme_light(base_size = 16) + #Changes base theme and also makes it have larger font 
  theme(panel.grid = element_blank(), #Customizing the background, removing gridlines 
        panel.background = element_rect(fill = "white",color = NA),
        plot.background = element_rect(fill = "white", color = NA),
        legend.position = "none") #Hides the legend 

```


#### c. Caption (5 points)

**Figure 1. Average time spent cooking(min) tends to be higher on School Days.** Data collected personally by Alexa Andrade. The points represent observations of daily time spent cooking(min) and are differentiated by whether the observations were taken on school(n=24) or non-school(n=10) days(total n=34). Colors represent the status of the day(red = non-school day, blue = school day). The graph represents the comparison between mean time spent cooking on different types of days, represented by the large black point, ± standard error(SE) bar whiskers between school days and non-school days.

#### d. Table presentation (10 points)


```{r}

Cooking_summary <- Cooking_summary |> 
  mutate(school_day = recode(school_day, #Renaming the categories in school_day column 
                             "N" = "Non-School Day",
                             "Y" = "School Day"))

Cooking_summary |>
  flextable() |> #Creating a summary statistics table 
  set_header_labels( #Renaming column headers for display
    school_day = "Status of Day",
    mean = "Mean",
    sd = "Standard Deviation",
    se = "Standard Error",
    ci_lower = "95% CI Lower",
    ci_upper = "95% CI Upper" ) |>
  set_caption("Summary Statistics of Cooking Time by School Day") |> #Adding a title to the table 
  autofit() #Adjusts column widths to fit content 



```



### Problem 2. Affective visualization (24 points)

#### a. Describe in words what an affective visualization could look like for your personal data (3-5 sentences). (2 points)

For my personal data I was inspired by Jill Pelto's "Seabirds of Seal Island" data visualization, so I also want to do a scenic affective visualization. I want to have the setting be a kitchen, and have two different countertops that represent two different approaches to preparing food for the day, one where their is a microwave and airfryer, and the other where there is a stove with cooking appliances. Between the two stoves, there is going to be shelves that are filled with a different number of ingredients and a differently sized spoon next to them to symbolize the proportion of dirty dishes used. Each cooking appliance on the stoves will be nect to or hold a bowl that is varying degrees of filled, representing the amount of time that would typically be spent ccoking there.

::: callout-tip
Try committing and pushing your changes here! Write an \_informative\_ commit message.
:::

#### b. Create a sketch (on paper) of your idea. (2 points)

![Rough Sketch of Visualization](Sketch.png)

::: callout-tip
Try committing and pushing your changes here! Write an \_informative\_ commit message.

Double check your rendered URL to make sure the photo of your sketch shows up.
:::

#### c. Make a draft of your visualization. (12 points)

![Draft of Visualization](Draft.png)

::: callout-tip
Try committing and pushing your changes here! Write an \_informative\_ commit message.

If you are including a photo, double check your rendered URL to make sure the photo of your draft shows up.
:::

#### d. Write an artist statement. (8 points)

An artist statement gives the audience context to understand your work. For each of the following points, write 1-2 sentences to address:

-   the content of your piece (what are you showing?)
-   the influences (what did techniques/artists/etc. did you find influential in creating your work?)
-   the form of your work (written code, watercolor, oil painting, etc.)
-   your process (how did you create your work?)

::: callout-tip
Try committing and pushing your changes here! Write an \_informative\_ commit message.
:::

::: {.callout-note title="This is prep for workshop during week 9!"}
During week 9, we will send time providing peer review for your affective visualization. If you turn in your homework next Wednesday, you will have a draft of your affective visualization that is ready for peer review.
:::

### Problem 3. Statistical critique (36 points)

At this point, you have seen and created a lot of figures for this class. Revisit the paper you chose for your critique and your homework 2, where you described figures or tables in the text. Address the following in full sentences (3-4 sentences each).

\*\*For this section of your homework, you will be evaluated on the logic, conciseness, and nuance of your critique.\*\*

#### a. Revisit and summarize (6 points)

A two-tailed Student’s t-test and a two-way mixed AVOLVA was conducted to answer the author's main research question: : Could mammalian cells retain a faithful copy of epigenetic information from earlier in life, which could serve as a guide in reversing aging? The response variable was axon regeneration and axon density, while the predictor variable was drug treatment of intravitreal injection of Adeno-Associated-Viruses that delivered OSK genes into the mice.The two-tailed student t-test was used to compare axon density and retinal ganglion counts between OSK gene-treated groups, so a significant result of a p-value less than 0.05 would mean that the OSK treatment led to reliable regeneration of axon density, supporting the paper’s hypothesis that epigenetic reprogramming can help reverse vision loss.

## Figure: Axon Density and Regeneration

![Axon density and regeneration](Axon_density.png)

::: callout-tip
Try committing and pushing your changes here! Write an \_informative\_ commit message.
:::

#### b. Visual clarity (10 points)

The authors did a clear job of logically labelling their axis and different control and treatment groups with color. However, the positioning of the p-values above the graph makes it unclear which p-value is for which comparison. The figure does show mean with Standard error bars, with the underlying data points being displayed for visual clarity.

::: callout-tip
Try committing and pushing your changes here! Write an \_informative\_ commit message.
:::

#### c. Aesthetic clarity (10 points)

I believe the authors handelled their visual clutter moderately well, as they ensured their were no background lines or grids that weren't actively symbolizing data. However, the data:ink ratio is not as maximized as it could be, with the P-values from the comparisons between the groups being unessessarily underlined and larger than what I think is reasonable, adding more ink to the figure while not adding more information about the data.

::: callout-tip
Try committing and pushing your changes here! Write an \_informative\_ commit message.
:::

#### d. Recommendations (can be longer than 4 sentences, 10 points)

What recommendations would you make to make the figure or table better? What would you take out, add, or change? Provide explanations/justifications for each of your recommendations.

To improve the aesthetic clarity of the figure, I recommend reducing the visual clutter by removing the underlining under the p-values. While I'm sure the underlines we're added to emphasize the p-values, I think that because the p-values are already located in a empty space and the underlines don't convey any statistical information, that removing them would be improve the data:ink ratio of the figure. I also recommend making the font size of the p-values smaller and adding subtle brackets labelling which p-value is for which comparisons between groups would lead to a higher data -making the underlying data slightly transparent

To enhance clarity, I would also add subtle connecting lines or brackets that clearly indicate which groups each p-value comparison refers to—this would prevent ambiguity about what is being tested. Finally, I suggest ensuring even spacing between bars and labels, which would improve visual flow and help the viewer focus more directly on the data trends."

::: callout-tip
Try committing and pushing your changes here! Write an \_informative\_ commit message.
:::

## 
